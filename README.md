# LLMRecProject
Design of a Recommendation Data Augmentation and Evaluation Method Based on Large Language Models.
Details:Cold-start users and the lack of real user feedback have long posed significant challenges to the performance and iterative development of recommendation systems. To address these limitations, this paper proposes a novel data augmentation and evaluation framework powered by large language models (LLMs), aiming to simultaneously alleviate user profile sparsity and the difficulty of evaluating recommendation effectiveness. The framework consists of two key modules: first, user interest completion is performed by semantically expanding sparse interaction data of cold-start users using LLMs, enabling the construction of more expressive user profiles. Second, after generating recommendation results, the system leverages LLMs to simulate user feedback by generating natural language-based satisfaction assessments. By building semantic contexts between users and items, the model produces structured or interpretable evaluation statements to support recommendation analysis and model optimization. We implement a prototype system based on the MovieLens-100K dataset and validate it using a traditional collaborative filtering algorithm. Experimental results demonstrate that the proposed method significantly enhances the recommendation quality for cold-start scenarios at a low computational cost, while offering strong interpretability and practical application potential.
